# Learning Resources for Live2D

# Apple Official Documents

## Vision

https://developer.apple.com/documentation/vision/tracking_the_user_s_face_in_real_time

Vision uses 2d images to detect face.

## ARKit

https://developer.apple.com/documentation/arkit/content_anchors/tracking_and_visualizing_faces

ARKit uses true depth front camera to detect face model.

# GitHub Project: ARKit-live2d

https://github.com/mzyy94/ARKit-Live2D

Use this project to use ARKit to capture your face and cast the parameters to live2d models.
 
If you want to use the live2d model to stream on Mac, just set the background to green and use OBS to access the screen mirror of iPhone or iPad. Check https://www.mzyy94.com/blog/2020/02/25/virtual-bishoujo-meeting/ for more information.

# Live2D Official

SDK manual https://docs.live2d.com/cubism-sdk-manual/top/?locale=en_us 

SDK tutorials https://docs.live2d.com/cubism-sdk-tutorials/top/?locale=en_us

Download SDK of live2d for Native https://www.live2d.com/en/download/cubism-sdk/download-native/
